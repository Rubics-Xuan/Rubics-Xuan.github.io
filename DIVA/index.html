<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DIVA">
  <meta property="og:title" content="DIVA"/>
  <meta property="og:description" content="Diffusion Feedback Helps CLIP See Better"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/video_t1.png" />
  <meta property="og:image:width" content="2412"/>
  <meta property="og:image:height" content="1394"/>


  <meta name="twitter:title" content="DIVA">
  <meta name="twitter:description" content="Diffusion Feedback Helps CLIP See Better">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/video_t1.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Image-to-Video">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DIVA</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Diffusion Feedback Helps CLIP See Better</h1>
            <!-- <h3 class="title is-3">CVPR 2024</h3> -->
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=75OyC-oAAAAJ&hl=zh-CN" target="_blank">Wenxuan Wang*</a><sup>1,2,3</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.cz/citations?user=pVKiHdEAAAAJ&hl=zh-CN&oi=ao" target="_blank">Quan Sun*</a><sup>3</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.cz/citations?hl=zh-CN&user=VsJ39HMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Fan Zhang</a><sup>3</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.cz/citations?user=CAC_4OUAAAAJ&hl=zh-CN&oi=ao" target="_blank">Yepeng Tang</a><sup>4</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=sOI-S7oAAAAJ&hl=zh-CN" target="_blank">Jing Liu</a><sup>1,2</sup>,&nbsp;&nbsp;</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=DPz0DjYAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Xinlong Wang</a><sup>3</sup>,&nbsp;&nbsp;</span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Institute of Automation, Chinese Academy of Sciences (CASIA)</span>
                    <span class="author-block"><sup>2</sup>School of Artificial Intelligence, University of Chinese Academy of Sciences (UCAS)</span>
                    <span class="author-block"><sup>3</sup>Beijing Academy of Artificial Intelligence (BAAI)</span>
                    <span class="author-block"><sup>4</sup>Beijing Jiaotong University (BJTU)</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2407.20171" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Video link -->
                    <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>video</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/baaivision/DIVA" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2407.20171" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- Your image here -->
          <img src="static/images/introduction.png" alt="MY ALT TEXT"/>
          <p>
            Contrastive Language-Image Pre-training (CLIP) has become integral to various multimodal understanding tasks, serving as a backbone for models across multiple domains. However, recent studies reveal that CLIP struggles with distinguishing visual differences between similar images, which limits the perceptual capabilities of multimodal large language models (MLLMs) that rely on it. This work addresses these limitations by enhancing CLIP's ability to discern fine-grained visual details. Given the high cost associated with training CLIP from scratch, we explore a more feasible approach of fine-tuning CLIP. Directly collecting image-text pairs for fine-tuning is not only expensive but also constrained by data quality, and it can adversely affect CLIP's zero-shot performance. To mitigate these challenges, we propose a DIffusion-based self-supervised framework as a Visual Assistant for CLIP, named DIVA. Our method leverages generative feedback from text-to-image diffusion models, utilizing only images (without corresponding text) to refine CLIP representations. It integrates dense visual features from CLIP as conditioning inputs for the diffusion process. We demonstrate that DIVA improves CLIP's performance on the MMVP-VLM benchmark to a large extent (i.e., ↑ around 3-7%), which assesses fine-grained visual abilities, and enhances the performance of MLLMs and vision models on multimodal understanding and semantic segmentation tasks. Extensive evaluations on 29 image classification and retrieval benchmarks confirm that our framework preserves CLIP's strong zero-shot capabilities.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">DIVA's Overall Architecture</h2>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/methodology.png" alt="MY ALT TEXT"/>
        <h2 class="content has-text-justified">
          
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

  
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Fine-grained Visual Perception Evaluation</h2>
      <div class="item" style="display: flex; justify-content: center; gap: 10px;">
        <!-- Your image here -->
        <img src="static/images/quantitative_mmvp.png" alt="MY ALT TEXT" style="max-width: 80%;/>
        <h2 class="content has-text-justified">
          
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Backbone Enhancement Performance Evaluation</h2>
      <div class="item" style="display: flex; justify-content: center; gap: 10px;">
        <!-- Your image here -->
        <img src="static/images/quantitative_backbone.png" alt="MY ALT TEXT" style="max-width: 80%;/>
        <h2 class="content has-text-justified">
          
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Generalization Capability Evaluation</h2>
      <div class="item" style="display: flex; justify-content: center; gap: 10px;">
        <!-- Your image here -->
        <img src="static/images/quantitative_generalization.png" alt="MY ALT TEXT" style="max-width: 80%;/>
        <h2 class="content has-text-justified">
          
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Qualitative Results</h2>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/qualitative_mmvp.png" alt="MY ALT TEXT"/>
        <h2 class="content has-text-justified">
          
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2024diffusion,
      title={Diffusion Feedback Helps CLIP See Better},
      author={Wang, Wenxuan and Sun, Quan and Zhang, Fan and Tang, Yepeng and Liu, Jing and Wang, Xinlong},
      journal={arXiv preprint arXiv:2407.20171},
      year={2024}
}</code></pre>
  </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<script>
bulmaCarousel.attach('#results-carousel11', {
    slidesToScroll: 1,
    slidesToShow: 2,
    infinite: true,
    autoplay: false,
});
bulmaCarousel.attach('#results-carousel22', {
    slidesToScroll: 1,
    slidesToShow: 2,
    infinite: true,
    autoplay: false,
});
bulmaCarousel.attach('#results-carousel33', {
    slidesToScroll: 1,
    slidesToShow: 2,
    infinite: true,
    autoplay: false,
});
</script>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
